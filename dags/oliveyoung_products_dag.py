"""
ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ ìˆ˜ì§‘ DAG
ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìƒí’ˆ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ GCSì— ì €ì¥
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
# Google Cloud providers - not needed for manual Cloud Run deployment
from airflow.models import Variable
from airflow.utils.dates import days_ago

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'dawit0905@gmail.com',
    'depends_on_past': False,
    'start_date': days_ago(1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'max_active_runs': 1,
}

# ì¹´í…Œê³ ë¦¬ ë”•ì…”ë„ˆë¦¬ (categories.pyì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°)
OLIVEYOUNG_CATEGORIES = {
    "ìŠ¤í‚¨ì¼€ì–´_ìŠ¤í‚¨/í† ë„ˆ": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=1000001000100130001&fltDispCatNo=&prdSort=01&pageIdx=1&rowsPerPage=24&searchTypeSort=btn_thumb&plusButtonFlag=N&isLoginCnt=1&aShowCnt=0&bShowCnt=0&cShowCnt=0&trackingCd=Cat1000001000100130001_Small&amplitudePageGubun=&t_page=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EC%83%81%EC%84%B8_%EC%86%8C%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&midCategory=%EC%8A%A4%ED%82%A8%2F%ED%86%A0%EB%84%88&smallCategory=%EC%A0%84%EC%B2%B4&checkBrnds=&lastChkBrnd=&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EC%8A%A4%ED%82%A8%2F%ED%86%A0%EB%84%88&t_3rd_category_type=%EC%86%8C_%EC%A0%84%EC%B2%B4",
    "ìŠ¤í‚¨ì¼€ì–´_ì—ì„¼ìŠ¤/ì„¸ëŸ¼/ì•°í”Œ": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010014&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&t_page=%EB%A1%9C%EC%BC%80%EC%9D%B4%EC%85%98_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EC%97%90%EC%84%BC%EC%8A%A4/%EC%84%B8%EB%9F%BC/%EC%95%B0%ED%94%8C",
    "ìŠ¤í‚¨ì¼€ì–´_í¬ë¦¼": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010015&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&t_page=%EB%A1%9C%EC%BC%80%EC%9D%B4%EC%85%98_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%ED%81%AC%EB%A6%BC",
    "ìŠ¤í‚¨ì¼€ì–´_ë¡œì…˜": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010016&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&t_page=%EB%A1%9C%EC%BC%80%EC%9D%B4%EC%85%98_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EB%A1%9C%EC%85%98",
    "ìŠ¤í‚¨ì¼€ì–´_ë¯¸ìŠ¤íŠ¸/ì˜¤ì¼": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010010&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&t_page=%EB%A1%9C%EC%BC%80%EC%9D%B4%EC%85%98_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EB%AF%B8%EC%8A%A4%ED%8A%B8/%EC%98%A4%EC%9D%BC",
    "ìŠ¤í‚¨ì¼€ì–´_ìŠ¤í‚¨ì¼€ì–´ì„¸íŠ¸": "https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010017&isLoginCnt=0&aShowCnt=0&bShowCnt=0&cShowCnt=0&t_page=%EB%A1%9C%EC%BC%80%EC%9D%B4%EC%85%98_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%EA%B4%80&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EC%A4%91%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4&t_2nd_category_type=%EC%A4%91_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4%EC%84%B8%ED%8A%B8",
}

# GCP ì„¤ì •
PROJECT_ID = "de6-2ez"
REGION = "asia-northeast3"
CLOUD_RUN_JOB_NAME = "oliveyoung-product-scraper"

def create_safe_task_id(category_name: str) -> str:
    """ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ Airflow task_idì— ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
    # ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ ì˜ë¬¸ìœ¼ë¡œ ë§¤í•‘
    category_mapping = {
        "ìŠ¤í‚¨ì¼€ì–´_ìŠ¤í‚¨/í† ë„ˆ": "skincare_skin_toner",
        "ìŠ¤í‚¨ì¼€ì–´_ì—ì„¼ìŠ¤/ì„¸ëŸ¼/ì•°í”Œ": "skincare_essence_serum_ampoule", 
        "ìŠ¤í‚¨ì¼€ì–´_í¬ë¦¼": "skincare_cream",
        "ìŠ¤í‚¨ì¼€ì–´_ë¡œì…˜": "skincare_lotion",
        "ìŠ¤í‚¨ì¼€ì–´_ë¯¸ìŠ¤íŠ¸/ì˜¤ì¼": "skincare_mist_oil",
        "ìŠ¤í‚¨ì¼€ì–´_ìŠ¤í‚¨ì¼€ì–´ì„¸íŠ¸": "skincare_sets"
    }
    
    return category_mapping.get(category_name, category_name.replace('/', '_').replace(' ', '_'))

def create_scraping_tasks(**context) -> List[Dict]:
    """ê° ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ ì‘ì—… ìƒì„±"""
    tasks = []
    execution_date = context['ds']
    
    for category_name, category_url in OLIVEYOUNG_CATEGORIES.items():
        task_info = {
            'category_name': category_name,
            'category_url': category_url,
            'execution_date': execution_date,
            'max_pages': 5,  # ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ í˜ì´ì§€ ìˆ˜
        }
        tasks.append(task_info)
    
    logger.info(f"Created {len(tasks)} scraping tasks")
    return tasks

def execute_category_scraping(category_name: str, category_url: str, max_pages: int = 5, **context):
    """ê°œë³„ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹¤í–‰"""
    from airflow.providers.http.operators.http import SimpleHttpOperator
    import requests
    
    # Cloud Run ì„œë¹„ìŠ¤ URL (ì‹¤ì œ ë°°í¬ í›„ ìˆ˜ì • í•„ìš”)
    cloud_run_url = f"https://{CLOUD_RUN_JOB_NAME}-{REGION}.run.app"
    
    # í¬ë¡¤ë§ ìš”ì²­ ë°ì´í„°
    scraping_data = {
        'category_name': category_name,
        'category_url': category_url,
        'max_pages': max_pages
    }
    
    try:
        logger.info(f"Starting scraping for category: {category_name}")
        
        # Cloud Run ì„œë¹„ìŠ¤ í˜¸ì¶œ
        response = requests.post(
            f"{cloud_run_url}/scrape",
            json=scraping_data,
            timeout=3600,  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
            headers={'Content-Type': 'application/json'}
        )
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"Successfully scraped {category_name}: {result}")
            return result
        else:
            error_msg = f"Failed to scrape {category_name}: {response.status_code} - {response.text}"
            logger.error(error_msg)
            raise Exception(error_msg)
            
    except Exception as e:
        logger.error(f"Error scraping category {category_name}: {str(e)}")
        raise

def deploy_product_scraper(**context):
    """ìƒí’ˆ í¬ë¡¤ëŸ¬ Cloud Run ì„œë¹„ìŠ¤ ë°°í¬"""
    import subprocess
    
    try:
        logger.info("ğŸ“¦ ìƒí’ˆ í¬ë¡¤ëŸ¬ Cloud Run ì„œë¹„ìŠ¤ ë°°í¬ ì‹œì‘...")
        
        # ì†ŒìŠ¤ ì½”ë“œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        source_dir = "/opt/airflow/scripts/cloud_run/product_scraper"
        docker_repo = f"{REGION}-docker.pkg.dev/{PROJECT_ID}/oliveyoung-scrapers"
        
        # 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ
        logger.info("ğŸ”¨ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘...")
        build_cmd = [
            'gcloud', 'builds', 'submit',
            '--tag', f'{docker_repo}/product-scraper:latest',
            '--project', PROJECT_ID,
            '--timeout', '20m',
            source_dir
        ]
        
        result = subprocess.run(build_cmd, capture_output=True, text=True, check=True)
        logger.info("âœ… Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ")
        
        # 2. Cloud Run ì„œë¹„ìŠ¤ ë°°í¬
        logger.info("ğŸš¢ Cloud Run ì„œë¹„ìŠ¤ ë°°í¬ ì¤‘...")
        deploy_cmd = [
            'gcloud', 'run', 'deploy', 'oliveyoung-product-scraper',
            '--image', f'{docker_repo}/product-scraper:latest',
            '--platform', 'managed',
            '--region', REGION,
            '--project', PROJECT_ID,
            '--memory', '4Gi',
            '--cpu', '2',
            '--timeout', '3600',
            '--max-instances', '10',
            '--set-env-vars', f'PROJECT_ID={PROJECT_ID},GCS_BUCKET={PROJECT_ID}-raw-data',
            '--service-account', f'dataproc-serverless-sa@{PROJECT_ID}.iam.gserviceaccount.com',
            '--no-allow-unauthenticated',
            '--quiet'
        ]
        
        result = subprocess.run(deploy_cmd, capture_output=True, text=True, check=True)
        logger.info("âœ… ìƒí’ˆ í¬ë¡¤ëŸ¬ Cloud Run ì„œë¹„ìŠ¤ ë°°í¬ ì™„ë£Œ")
        
        # 3. ì„œë¹„ìŠ¤ URL í™•ì¸
        url_cmd = [
            'gcloud', 'run', 'services', 'describe', 'oliveyoung-product-scraper',
            '--region', REGION,
            '--project', PROJECT_ID,
            '--format', 'value(status.url)'
        ]
        
        result = subprocess.run(url_cmd, capture_output=True, text=True, check=True)
        service_url = result.stdout.strip()
        logger.info(f"ğŸ“Š ì„œë¹„ìŠ¤ URL: {service_url}")
        
        return {
            'status': 'success',
            'service_url': service_url,
            'deployed_at': datetime.now().isoformat()
        }
        
    except subprocess.CalledProcessError as e:
        error_msg = f"ë°°í¬ ì‹¤íŒ¨: {e.stderr if e.stderr else str(e)}"
        logger.error(error_msg)
        raise Exception(error_msg)
    except Exception as e:
        error_msg = f"ë°°í¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_msg)
        raise Exception(error_msg)

def validate_scraping_results(**context):
    """í¬ë¡¤ë§ ê²°ê³¼ ê²€ì¦ ë° ìš”ì•½"""
    ti = context['ti']
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì‘ì—… ê²°ê³¼ ìˆ˜ì§‘
    total_products = 0
    successful_categories = []
    failed_categories = []
    
    for category_name in OLIVEYOUNG_CATEGORIES.keys():
        task_id = f"scrape_category_{create_safe_task_id(category_name)}"
        try:
            result = ti.xcom_pull(task_ids=task_id)
            if result and result.get('status') == 'completed':
                products_count = result.get('products_count', 0)
                total_products += products_count
                successful_categories.append({
                    'category': category_name,
                    'products_count': products_count,
                    'gcs_path': result.get('gcs_path')
                })
                logger.info(f"âœ… {category_name}: {products_count} products")
            else:
                failed_categories.append(category_name)
                logger.error(f"âŒ {category_name}: Failed")
        except Exception as e:
            failed_categories.append(category_name)
            logger.error(f"âŒ {category_name}: Exception - {str(e)}")
    
    # ê²°ê³¼ ìš”ì•½
    summary = {
        'execution_date': context['ds'],
        'total_categories': len(OLIVEYOUNG_CATEGORIES),
        'successful_categories': len(successful_categories),
        'failed_categories': len(failed_categories),
        'total_products_scraped': total_products,
        'successful_category_details': successful_categories,
        'failed_category_list': failed_categories,
        'scraping_completed_at': datetime.now().isoformat()
    }
    
    logger.info("=== ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ ===")
    logger.info(f"ì´ ì¹´í…Œê³ ë¦¬: {summary['total_categories']}")
    logger.info(f"ì„±ê³µ: {summary['successful_categories']}")
    logger.info(f"ì‹¤íŒ¨: {summary['failed_categories']}")
    logger.info(f"ì´ ìƒí’ˆ ìˆ˜: {summary['total_products_scraped']}")
    
    # ì‹¤íŒ¨í•œ ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´ ê²½ê³ 
    if failed_categories:
        logger.warning(f"ì‹¤íŒ¨í•œ ì¹´í…Œê³ ë¦¬: {failed_categories}")
    
    return summary

# DAG ìƒì„±
dag = DAG(
    'oliveyoung_products_collection',
    default_args=default_args,
    description='ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ í¬ë¡¤ëŸ¬ ë°°í¬ ë° ë°ì´í„° ìˆ˜ì§‘',
    schedule_interval=None,  # ìˆ˜ë™ ì‹¤í–‰ë§Œ
    catchup=False,
    max_active_runs=1,
    tags=['oliveyoung', 'products', 'scraping', 'deployment', 'manual'],
)

# Cloud Run ì„œë¹„ìŠ¤ ë°°í¬ íƒœìŠ¤í¬
deploy_service = PythonOperator(
    task_id='deploy_product_scraper_service',
    python_callable=deploy_product_scraper,
    execution_timeout=timedelta(minutes=30),
    dag=dag,
)

# ì‘ì—… ìƒì„± íƒœìŠ¤í¬
create_tasks = PythonOperator(
    task_id='create_scraping_tasks',
    python_callable=create_scraping_tasks,
    dag=dag,
)

# ê° ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ íƒœìŠ¤í¬ ë™ì  ìƒì„±
scraping_tasks = []

for category_name, category_url in OLIVEYOUNG_CATEGORIES.items():
    # íƒœìŠ¤í¬ IDì— ì‚¬ìš©í•  ì•ˆì „í•œ ì´ë¦„ ìƒì„±
    safe_category_name = create_safe_task_id(category_name)
    
    scraping_task = PythonOperator(
        task_id=f'scrape_category_{safe_category_name}',
        python_callable=execute_category_scraping,
        op_kwargs={
            'category_name': category_name,
            'category_url': category_url,
            'max_pages': 5,
        },
        dag=dag,
        pool='default_pool',  # ê¸°ë³¸ í’€ ì‚¬ìš©
    )
    
    scraping_tasks.append(scraping_task)

# ê²°ê³¼ ê²€ì¦ íƒœìŠ¤í¬
validate_results = PythonOperator(
    task_id='validate_scraping_results',
    python_callable=validate_scraping_results,
    dag=dag,
)

# ì™„ë£Œ ì•Œë¦¼ íƒœìŠ¤í¬
completion_notification = BashOperator(
    task_id='completion_notification',
    bash_command='''
    echo "=== ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ ==="
    echo "ì‹¤í–‰ ë‚ ì§œ: {{ ds }}"
    echo "ì™„ë£Œ ì‹œê°: $(date)"
    echo "ë‹¤ìŒ ë‹¨ê³„: ë¦¬ë·° í¬ë¡¤ë§ DAG ì‹¤í–‰ ê°€ëŠ¥"
    ''',
    dag=dag,
)

# íƒœìŠ¤í¬ ì˜ì¡´ì„± ì„¤ì •
# 1. ë¨¼ì € Cloud Run ì„œë¹„ìŠ¤ ë°°í¬
# 2. ë°°í¬ ì™„ë£Œ í›„ í¬ë¡¤ë§ ì‘ì—… ìƒì„±
# 3. ê° ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ ë³‘ë ¬ ì‹¤í–‰
# 4. ê²°ê³¼ ê²€ì¦ ë° ì™„ë£Œ ì•Œë¦¼

deploy_service >> create_tasks >> scraping_tasks >> validate_results >> completion_notification

# ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì •
for task in scraping_tasks:
    create_tasks >> task
